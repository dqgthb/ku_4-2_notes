# Today's class

## Local Search Space

$$
w_1a_1 + w_2a_2 + w0 = 0
$$

뭔가를 조정을 해가지고 낮게 가야 하는데, 각각의 state 의 점수가 뭐냐? error 값이다.

$$
\vec{o}^{\,t}
$$

각각의 state이 w의 집합이다. error값이 달라진다. 그래서 우리가 찾는 것은 error 값이 제일 작은 것을 어떻게 찾을 것인가?

Error값이 제일 작은 위치에서의 w값을 쓰겠다!

$$
E = \frac{1}{2} \sum{(T-O)^2}
$$

수학적으로 미적분을 취하게 된다.

$$
\frac{\delta{E}}{\delta{W}} = 0
$$

를 만족하는 W를 찾는 작업이다.

이 과정을 gradient descent라고 얘기한다.

델타 룰에서는 퍼셉트론에 적용을 했기 때문에 노드가 하나고 스탭펑션이다. 그래서 이런 델타룰의 형태로 나온건데, MLP에서는 어떻게 해결할 것이냐?

30초만 그림 보고 넘어가자.

학습시키는 알고리즘을 알 수가 없어서 뉴럴넷의 겨울이 시작되었다가,
힌튼 교수가 back-propagation 으로 이걸 해결하는 gradient descent 알고리즘을 가지고 나옵니다.

그런 배경으로 시작이 되었다고 할 수 있습니다.

## MLP (Multi-Layered Perceptron)

1. MLP의 학습 알고리즘은 gradient descent 그대로 쓰면 된다.
2. Optimal architecture 구조를 어떻게 알 수가 있을까? How many hidden units? hidden layers? How to fix it?
3. Feature dimension? 모든 feature를 다 집어넣으면 overfit의 위험이 있다. 어떻게 뽑을 것인가?
4. Interpretation: 어떻게 이해를 하고 설명을 할 것인가?

*20초간 보고~ 질문 있으면 하시구요~*

Input data는 Numerical binary data를 쓴다. Categorical이라면? binary로 바꾸면 된다~

Class 별로 하나씩 넣는 것이 일반적이다.

How many hidden layers?

- One hidden layer: convex

- Two: arbitrary decision boundaries
- Three: convoluted

> Hidden Layer의 역할은? Non-linearity를 잘 뽑아내기 위한 것!

Iris 데이터 예시: input이 A1, A2이고, hidden unit은 안 썼고, output은 3개.

단점:

- Slow
- Hidden layer가 많아지면 성능 저하
- Local minimum $\rightarrow$ stochastic한 방법을 써서 빠져나온다.
- architecture (hidden unit 개수)
- 해석이 어렵다
- learning is not incremental

NN의 처음 시작

1. 학습전략
2. hidden layer numbers
3. feature selection, feature space
4. interpretation

## Backpropagation learning

Perceptron의 Delta rule과 비교하여 생각해 볼 것

$$
f'(x) = 0
$$

$$
\frac{\Delta{E}}{\Delta{W}} = 0
$$

으로 이 weight값을 찾을 수 있다. 

$$
w = w + r \cdot \delta \cdot w
$$
